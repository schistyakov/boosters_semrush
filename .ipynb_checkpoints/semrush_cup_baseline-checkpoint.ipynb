{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data\n",
    "\n",
    "Demographics and category data (`semrush_cup_categories_and_demo.csv`) are read but not used in the basic solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('semrush_cup_train_data.csv')\n",
    "val = pd.read_csv('semrush_cup_test_data.csv')\n",
    "val['is_referrer'] = False\n",
    "\n",
    "cats_and_demo = pd.read_csv('semrush_cup_categories_and_demo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids_list = train['device_id'].unique()\n",
    "stat_uids, train_uids = train_test_split(uids_list, train_size=0.7, random_state=0)\n",
    "train_uids, test_uids = train_test_split(train_uids, train_size=0.7, random_state=0)\n",
    "\n",
    "stat_data = train.loc[train['device_id'].isin(stat_uids)]\n",
    "train_data = train.loc[train['device_id'].isin(train_uids)]\n",
    "test_data = train.loc[train['device_id'].isin(test_uids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сalculation of statistics\n",
    "\n",
    "Here we calculate statistics for traffic sources.  \n",
    "Most of the data were used for the calculation, as this information will be the basis for generating the basic solution features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pair_devices_count = stat_data.groupby(['domain', 'referrer_domain'])['device_id'].nunique().to_dict()\n",
    "is_referrer_devices_count = stat_data.groupby('referrer_domain')['device_id'].nunique().to_dict()\n",
    "is_referrer_count = stat_data.groupby('referrer_domain')['domain'].nunique().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating features\n",
    "\n",
    "Based on statistics, we generate features: \n",
    "- `is_referrer_count` – For how many domains the domain from the previous event acted as a referral for.\n",
    "- `is_referrer_devices_count` –  How popular the domain is as a referral by different devices.\n",
    "- `pair_devices_count` – How often the pair met as a domain referral.\n",
    "- `is_referrer_prob` – The \"probability\" of the domain being a referral for the target event.\n",
    "\n",
    "Other features:\n",
    "- `delta_time` – The time between two events.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_features(event_group, pair_devices_count, is_referrer_devices_count, is_referrer_count):\n",
    "    event_group = event_group.sort_values('timestamp')\n",
    "    target_row = event_group.loc[event_group['referrer_num'] == 'target']\n",
    "\n",
    "    domain = target_row['domain'].values[0]\n",
    "\n",
    "    features = event_group[['device_id', 'event_group_id', 'referrer_num', 'is_referrer']].copy()\n",
    "    features['delta_time'] = target_row['timestamp'].values[0] - event_group['timestamp']\n",
    "\n",
    "    features['is_referrer_count'] = event_group['domain'].apply(lambda x: is_referrer_count.get(x, 0))\n",
    "    features['is_referrer_devices_count'] = event_group['domain'].apply(lambda x: is_referrer_devices_count.get(x, 0))\n",
    "    features['pair_devices_count'] = event_group['domain'].apply(lambda x: pair_devices_count.get((domain,x), 0))\n",
    "    features['is_referrer_prob'] = features['pair_devices_count']/features['is_referrer_devices_count']\n",
    " \n",
    "    # Deleting the event the referral is predicted for.\n",
    "    features = features.loc[features['referrer_num'] != 'target']\n",
    "\n",
    "    return features.reset_index(drop=True)\n",
    "\n",
    "func = partial(create_features, \n",
    "               pair_devices_count=pair_devices_count, \n",
    "               is_referrer_devices_count=is_referrer_devices_count, \n",
    "               is_referrer_count=is_referrer_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 4s, sys: 2min 7s, total: 24min 11s\n",
      "Wall time: 23min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with Pool(32) as pool:\n",
    "    args = [g for _, g in train_data.groupby(['device_id', 'event_group_id'])]\n",
    "    train_features = pd.concat(pool.map(func, args))\n",
    "    \n",
    "    args = [g for _, g in test_data.groupby(['device_id', 'event_group_id'])]\n",
    "    test_features = pd.concat(pool.map(func, args))\n",
    "    \n",
    "    args = [g for _, g in val.groupby(['device_id', 'event_group_id'])]\n",
    "    val_features = pd.concat(pool.map(func, args))\n",
    "    \n",
    "feature_names = train_features.columns[4::]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "\n",
    "Before the training, we balance data to get the same number of referrals from each position (0 to 9).  \n",
    "The closer two events are, the more likely there was a referral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train f1: 0.8436456831136696\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=3, n_estimators=111,  \n",
    "                        use_label_encoder=False, random_state=0, nthread=32)\n",
    "\n",
    "min_size = train_features.groupby('is_referrer').size().min()\n",
    "stupidly_balanced = train_features.groupby('is_referrer').apply(lambda x: x.sample(min_size))\n",
    "train_X = stupidly_balanced[feature_names]\n",
    "train_y = stupidly_balanced['is_referrer']\n",
    "\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "print('train f1:', f1_score(train_y, clf.predict(train_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Since the model was trained for binary classification, we choose the answer from the maximum score among the 10 preceding events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = test_features[['event_group_id', 'is_referrer']].copy()\n",
    "predict['predict'] = clf.predict_proba(test_features[feature_names])[::, 1]\n",
    "\n",
    "true_values = predict.groupby('event_group_id').apply(lambda x: x['is_referrer'].argmax()).values\n",
    "predict_values = predict.groupby('event_group_id').apply(lambda x: x['predict'].argmax()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6596251632148219\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(true_values, predict_values, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1/precision/recall: 0.59 0.6 0.59\n",
      "f1/precision/recall: 0.6 0.61 0.59\n",
      "f1/precision/recall: 0.62 0.63 0.6\n",
      "f1/precision/recall: 0.61 0.61 0.6\n",
      "f1/precision/recall: 0.62 0.63 0.61\n",
      "f1/precision/recall: 0.64 0.64 0.64\n",
      "f1/precision/recall: 0.65 0.66 0.65\n",
      "f1/precision/recall: 0.68 0.67 0.69\n",
      "f1/precision/recall: 0.72 0.7 0.74\n",
      "f1/precision/recall: 0.87 0.87 0.86\n"
     ]
    }
   ],
   "source": [
    "f1 = np.round(f1_score(true_values, predict_values, average=None), 2)\n",
    "precision = np.round(precision_score(true_values, predict_values, average=None), 2)\n",
    "recall = np.round(recall_score(true_values, predict_values, average=None), 2)\n",
    "for f, p, r in zip(f1, precision, recall):\n",
    "    print('f1/precision/recall:', f, p, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = val_features[['event_group_id']].copy()\n",
    "ans['predict'] = clf.predict_proba(val_features[feature_names])[::, 1]\n",
    "\n",
    "ans = ans.groupby('event_group_id').apply(lambda x: x['predict'].argmax())\n",
    "ans = ans.reset_index()\n",
    "ans = ans.rename(columns={0:'referrer_num'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
